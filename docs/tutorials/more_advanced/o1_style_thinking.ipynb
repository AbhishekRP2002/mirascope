{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# o1 Style Thinking\n",
    "\n",
    "In this recipe, we will show how to achieve Chain-of-Thought Reasoning.\n",
    "This makes LLMs to breakdown the task in multiple steps and generate a coherent output allowing to solve complex tasks in logical steps.\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "<p class=\"admonition-title\">Mirascope Concepts Used</p>\n",
    "<ul>\n",
    "<li><a href=\"../../../learn/prompts/\">Prompts</a></li>\n",
    "<li><a href=\"../../../learn/calls/\">Calls</a></li>\n",
    "<li><a href=\"../../../learn/response_models/\">Response Models</a></li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<div class=\"admonition note\">\n",
    "<p class=\"admonition-title\">Background</p>\n",
    "<p>\n",
    "    Large Language Models (LLMs) are known to generate text that is coherent and fluent. However, they often struggle with tasks that require multi-step reasoning or logical thinking. In this recipe, we will show how to use Mirascope to guide the LLM to break down the task into multiple steps and generate a coherent output.\n",
    "\n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "To set up our environment, first let's install all of the packages we will use:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"mirascope[groq]\" \n",
    "!pip install datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Set the appropriate API key for the provider you're using\n",
    "# Here we are using GROQ_API_KEY\n",
    "\n",
    "export GROQ_API=\"Your API Key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mirascope.core import groq\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Chain-of-Thought Reasoning\n",
    "\n",
    "We will begin by showing how a typical LLM performs on a task that requires multi-step reasoning. In this example, we will ask the model to generate a count the number of `s`s in the word `Mississssippi` (Yes it has 7`s`'s). We will use the `llama-3.1-8b-instant` for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(User): how many s's in the word mississssippi\n",
      "(Assissant): The word \"mississippi\" contains 4 's' characters.\n"
     ]
    }
   ],
   "source": [
    "history: list[dict] = []\n",
    "\n",
    "\n",
    "@groq.call(\"llama-3.1-8b-instant\")\n",
    "def generate_answer(question: str) -> str:\n",
    "    return f\"Generate an answer to this question: {question}\"\n",
    "\n",
    "\n",
    "def run():\n",
    "    question = \"how many s's in the word mississssippi\"\n",
    "    response = generate_answer(question)\n",
    "    print(f\"(User): {question}\")\n",
    "    print(f\"(Assissant): {response}\")\n",
    "    history.append({\"role\": \"user\", \"content\": question})\n",
    "    history.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "\n",
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the zero-shot method is used to generate the output. The model is not provided with any additional information or context to help it generate the output. The model is only given the input prompt and asked to generate the output.\n",
    "\n",
    "This is not so effective when there is a logcial task to be performed.\n",
    "\n",
    "Now let's see how the model performs on this task when it can reason using Chain-of-Thought Reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Chain of Thought Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(User): how many s's in the word mississssippi\n",
      "Step 1: Identify the task:\n",
      "<think>To solve this task, we need to count the number of 's's in the word \"mississssippi\". This involves:\n",
      "\n",
      "1. Breaking down the word \"mississssippi\" into individual letters.\n",
      "2. Counting the number of 's's in the word.\n",
      "\n",
      "The word \"mississssippi\" can be broken down as follows: \n",
      "\n",
      "m - i - s - s - i - s - s - s - s - s - i - p - p - i\n",
      "\n",
      "Now, counting the 's's: 1. one 's', 2. 's', 3. 's', 4. 's', 5. 's', 6. 's'. Therefore, the word \"mississssippi\" contains 6 's's.\n",
      "\n",
      "The task is a simple linguistic exercise that involves character counting and string manipulation.</think>\n",
      "**Thinking time: 1.34 seconds**\n",
      "\n",
      "Step 2: Break down the task:\n",
      "<think>We will start by decomposing the word into its constituent parts. This will help us examine each letter individually and accurately count the number of 's's.</think>\n",
      "1.1 Decompose the word into individual letters:\n",
      "   m - i - s - s - i - s - s - s - s - s - i - p - p - i\n",
      "\n",
      "**Step 2: Identify the 's' characters**\n",
      "<think>Now that we have the word broken down, we need to locate and count all the occurrences of the letter 's'. This will involve examining each individual letter and checking if it matches the target character.</think>\n",
      "**Step 3: Count the number of 's's in the word**\n",
      "<think>Once we have located all the 's's, we simply need to count how many there are. This will give us the desired result, which is the total number of 's's in the word \"mississssippi\".</think>\n",
      "From the given word:\n",
      "1. one 's', \n",
      "2. 's', \n",
      "3. 's', \n",
      "4. 's', \n",
      "5. 's', \n",
      "6. 's'.\n",
      "**Thinking time: 1.56 seconds**\n",
      "\n",
      "Step 3: Execute the task:\n",
      "<think>We will start by decomposing the word into its constituent parts. This will help us examine each letter individually and accurately count the number of 's's.</think>\n",
      "1.1 Decompose the word into individual letters:\n",
      "   m - i - s - s - i - s - s - s - s - s - i - p - p - i\n",
      "\n",
      "**Step 2: Identify the 's' characters**\n",
      "<think>Now that we have the word broken down, we need to locate and count all the occurrences of the letter 's'. This will involve examining each individual letter and checking if it matches the target character.</think>\n",
      "Based on the decomposition:\n",
      "- The first 's' comes after the 'm'.\n",
      "- The second 's' comes after the 's'.\n",
      "- The third 's' comes after the 's'.\n",
      "- The fourth 's' comes after the 's'.\n",
      "- The fifth 's' comes after the 's'.\n",
      "- The sixth 's' comes after the 's'.\n",
      "The 's' characters are:\n",
      "1. 's' (after 'm')\n",
      "2. 's' (after the first 's')\n",
      "3. 's' (after the second 's')\n",
      "4. 's' (after the third 's')\n",
      "5. 's' (after the fourth 's')\n",
      "6. 's' (after the fifth 's')\n",
      "There are a total of seven 's's in the word.\n",
      "\n",
      "**Step 3: Count the number of 's's in the word**\n",
      "<think>Once we have located all the 's's, we simply need to count how many there are. This will give us the desired result, which is the total number of 's's in the word \"mississssippi\".</think>\n",
      "Based on the identification of the 's' characters earlier, there are seven 's's in total.\n",
      "**Thinking time: 1.63 seconds**\n",
      "\n",
      "Final Answer:\n",
      "The total number of \"s\"s in the word \"mississssippi\" is 7.\n",
      "**Thinking time: 1.51 seconds**\n",
      "\n",
      "**Total thinking time: 6.05 seconds**\n"
     ]
    }
   ],
   "source": [
    "from mirascope.core import groq\n",
    "\n",
    "history: list[dict] = []\n",
    "\n",
    "\n",
    "@groq.call(\"llama-3.1-8b-instant\")\n",
    "def identify_task(question: str) -> str:\n",
    "    return f\"Identify the task in this question. Wrap your thoughts in <think></think> tags: {question}\"\n",
    "\n",
    "\n",
    "@groq.call(\"llama-3.1-8b-instant\")\n",
    "def break_down_task(task: str) -> str:\n",
    "    return f\"Break down this task into steps. Wrap your thoughts in <think></think> tags: {task}\"\n",
    "\n",
    "\n",
    "@groq.call(\"llama-3.1-8b-instant\")\n",
    "def execute_task(steps: str) -> str:\n",
    "    return f\"Execute these steps to solve the task. Wrap your thoughts in <think></think> tags: {steps}\"\n",
    "\n",
    "\n",
    "@groq.call(\"llama-3.1-8b-instant\")\n",
    "def final_answer(execution: str) -> str:\n",
    "    return f\"Based on this execution, provide a final answer. Do not use <think></think> tags for the final answer: {execution}\"\n",
    "\n",
    "\n",
    "def generate_cot_response(user_query):\n",
    "    steps = []\n",
    "    total_thinking_time = 0.0\n",
    "\n",
    "    # Step 1: Identify the task\n",
    "    start_time = datetime.now()\n",
    "    identify_result = identify_task(user_query)\n",
    "    end_time = datetime.now()\n",
    "    thinking_time = (end_time - start_time).total_seconds()\n",
    "    steps.append((\"Step 1: Identify the task\", identify_result.content, thinking_time))\n",
    "    total_thinking_time += thinking_time\n",
    "\n",
    "    # Step 2: Break down the task\n",
    "    start_time = datetime.now()\n",
    "    breakdown_result = break_down_task(identify_result.content)\n",
    "    end_time = datetime.now()\n",
    "    thinking_time = (end_time - start_time).total_seconds()\n",
    "    steps.append(\n",
    "        (\"Step 2: Break down the task\", breakdown_result.content, thinking_time)\n",
    "    )\n",
    "    total_thinking_time += thinking_time\n",
    "\n",
    "    # Step 3: Execute the task\n",
    "    start_time = datetime.now()\n",
    "    execute_result = execute_task(breakdown_result.content)\n",
    "    end_time = datetime.now()\n",
    "    thinking_time = (end_time - start_time).total_seconds()\n",
    "    steps.append((\"Step 3: Execute the task\", execute_result.content, thinking_time))\n",
    "    total_thinking_time += thinking_time\n",
    "\n",
    "    # Final answer\n",
    "    start_time = datetime.now()\n",
    "    final_result = final_answer(execute_result.content)\n",
    "    end_time = datetime.now()\n",
    "    thinking_time = (end_time - start_time).total_seconds()\n",
    "    steps.append((\"Final Answer\", final_result.content, thinking_time))\n",
    "    total_thinking_time += thinking_time\n",
    "\n",
    "    return steps, total_thinking_time\n",
    "\n",
    "\n",
    "def display_cot_response(steps, total_thinking_time):\n",
    "    for title, content, thinking_time in steps:\n",
    "        print(f\"{title}:\")\n",
    "        if \"<think>\" in content and \"</think>\" in content:\n",
    "            think_parts = content.split(\"<think>\")\n",
    "            for part in think_parts[\n",
    "                1:\n",
    "            ]:  # Skip the first split as it's before any <think> tag\n",
    "                thought, remaining = part.split(\"</think>\", 1)\n",
    "                print(f\"<think>{thought.strip()}</think>\")\n",
    "                if remaining.strip():\n",
    "                    print(remaining.strip())\n",
    "        else:\n",
    "            print(content.strip())\n",
    "        print(f\"**Thinking time: {thinking_time:.2f} seconds**\\n\")\n",
    "\n",
    "    print(f\"**Total thinking time: {total_thinking_time:.2f} seconds**\")\n",
    "\n",
    "\n",
    "def run():\n",
    "    question = \"how many s's in the word mississssippi\"\n",
    "    print(\"(User):\", question)\n",
    "    # Generate COT response\n",
    "    steps, total_thinking_time = generate_cot_response(question)\n",
    "    display_cot_response(steps, total_thinking_time)\n",
    "\n",
    "    # Add the interaction to the history\n",
    "    history.append({\"role\": \"user\", \"content\": question})\n",
    "    history.append(\n",
    "        {\"role\": \"assistant\", \"content\": steps[-1][1]}\n",
    "    )  # Add only the final answer to the history\n",
    "\n",
    "\n",
    "# Run the the function\n",
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As demonstrated in the COT Reasoning example, we can guide the model to break down the task into multiple steps and generate a coherent output. This allows the model to solve complex tasks in logical steps.\n",
    "However, this requires multiple calls to the model, which may be expensive in terms of cost and time.\n",
    "Also model may not always identify the correct steps to solve the task, hence is not deterministic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Chain of Thought Reasoning is a powerful technique that allows LLMs to solve complex tasks in logical steps. However, it requires multiple calls to the model and may not always identify the correct steps to solve the task. This technique can be useful when the task requires multi-step reasoning or logical thinking.\n",
    "\n",
    "Care should be taken to ensure that the model is guided correctly and that the output is coherent and accurate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
