{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e64fd8485eae1ce8",
   "metadata": {},
   "source": [
    "# Text Summarization\n",
    "\n",
    "In this recipe, we show some techniques to improve an LLM’s ability to summarize a long text from simple (e.g. `\"Summarize this text: {text}...\"`) to more complex prompting and chaining techniques. We will use OpenAI’s GPT-4o-mini model (128k input token limit), but you can use any model you’d like to implement these summarization techniques, as long as they have a large context window.\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "<p class=\"admonition-title\">Mirascope Concepts Used</p>\n",
    "<ul>\n",
    "<li><a href=\"../../../learn/prompts/\">Prompts</a></li>\n",
    "<li><a href=\"../../../learn/calls/\">Calls</a></li>\n",
    "<li><a href=\"../../../learn/response_models/\">Response Models</a></li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"admonition note\">\n",
    "<p class=\"admonition-title\">Background</p>\n",
    "<p>\n",
    "    Large Language Models (LLMs) have revolutionized text summarization by enabling more coherent and contextually aware abstractive summaries. Unlike earlier models that primarily extracted or rearranged existing sentences, LLMs can generate novel text that captures the essence of longer documents while maintaining readability and factual accuracy.\n",
    "\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "## Simple Call\n",
    "\n",
    "For our examples, we’ll use the [Wikipedia article on python](https://en.wikipedia.org/wiki/Python_(programming_language)). We will be referring to this article as `wikipedia-python.txt`.\n",
    "\n",
    "The command below will download the article to your local machine by using the `curl` command. If you don't have `curl` installed, you can download the article manually from the link above and save it as `wikipedia-python.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2819ce3328bbe15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T05:41:43.998433Z",
     "start_time": "2024-09-30T05:41:43.250482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100  166k  100  166k    0     0   273k      0 --:--:-- --:--:-- --:--:--  273k\r\n"
     ]
    }
   ],
   "source": [
    "!curl \"https://en.wikipedia.org/wiki/Guido_van_Rossum\" -o wikipedia-guido_van_rossum.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9239559682ba47",
   "metadata": {},
   "source": "We will be using a simple call as our baseline:"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e7f9a366601cc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T05:49:32.712Z",
     "start_time": "2024-09-30T05:49:27.850275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guido van Rossum is a Dutch programmer, best known as the creator of the Python programming language. Born on January 31, 1956, in The Hague, he graduated with a master's degree in mathematics and computer science from the University of Amsterdam in 1982. Van Rossum developed Python in December 1989 as a hobby project during the Christmas holidays. He served as the \"benevolent dictator for life\" (BDFL) of Python until he stepped down in July 2018. He has worked with various organizations, including Centrum Wiskunde & Informatica, Google, Dropbox, and currently Microsoft as a Distinguished Engineer. Van Rossum continues to contribute significantly to Python's development and the wider programming community. He has received several awards for his contributions, including the Award for the Advancement of Free Software and the C&C Prize.\n"
     ]
    }
   ],
   "source": [
    "from mirascope.core import openai, prompt_template\n",
    "\n",
    "with open(\"wikipedia-guido_van_rossum.html\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "\n",
    "@openai.call(model=\"gpt-4o-mini\")\n",
    "@prompt_template(\n",
    "    \"\"\"\n",
    "    Summarize the following text:\n",
    "    {text}\n",
    "    \"\"\"\n",
    ")\n",
    "def simple_summarize_text(text: str): ...\n",
    "\n",
    "\n",
    "print(simple_summarize_text(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd61e2b111a9671",
   "metadata": {},
   "source": [
    "LLMs excel at summarizing shorter texts, but they often struggle with longer documents, failing to capture the overall structure while sometimes including minor, irrelevant details that detract from the summary's coherence and relevance.\n",
    "\n",
    "One simple update we can make is to improve our prompt by providing an initial outline of the text then adhere to this outline to create its summary.\n",
    "\n",
    "# Simple Call with Outline\n",
    "\n",
    "This prompt engineering technique is an example of [Chain of Thought](https://www.promptingguide.ai/techniques/cot) (CoT), forcing the model to write out its thinking process. It also involves little work and can be done by modifying the text of the single call. With an outline, the summary is less likely to lose the general structure of the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8616577753a9993",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T05:49:50.083470Z",
     "start_time": "2024-09-30T05:49:36.325207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Outline\n",
      "\n",
      "1. **Introduction**\n",
      "   - Brief Overview\n",
      "   - Notable Role as Python Creator\n",
      "\n",
      "2. **Personal Life**\n",
      "   - Birth and Early Life\n",
      "   - Education and Academic Achievements\n",
      "   - Family Life\n",
      "\n",
      "3. **Career Milestones**\n",
      "   - Early Work (Centrum Wiskunde & Informatica)\n",
      "   - Contributions to Python Development\n",
      "   - Roles at Prominent Companies\n",
      "     - Google\n",
      "     - Dropbox\n",
      "     - Microsoft\n",
      "\n",
      "4. **Contributions to Python**\n",
      "   - Development of Python\n",
      "   - Notable Achievements and Innovations\n",
      "   - Impact on Programming Community\n",
      "\n",
      "5. **Awards and Recognition**\n",
      "   - Honors and Awards Received \n",
      "   - Notable Recognitions in the Tech Community\n",
      "\n",
      "6. **Conclusion**\n",
      "   - Retirement and Current Status\n",
      "   - Legacy in Programming\n",
      "\n",
      "### Summary\n",
      "\n",
      "Guido van Rossum, born on January 31, 1956, in The Hague, Netherlands, is a prominent computer programmer best known for creating the Python programming language, where he previously served as the \"benevolent dictator for life\" until stepping down in July 2018. He obtained a master's degree in mathematics and computer science from the University of Amsterdam in 1982.\n",
      "\n",
      "Throughout his career, van Rossum has held influential roles in major tech companies. He began his career at Centrum Wiskunde & Informatica, where he contributed to the development of the glob() routine for BSD Unix and helped in creating the ABC programming language. He later joined Google and played a significant role in Python's ongoing development before moving to Dropbox in 2013. Recently, in November 2020, he announced his return from retirement to work at Microsoft as a Distinguished Engineer.\n",
      "\n",
      "Van Rossum's key achievement is the creation of Python, initiated as a hobby project during Christmas 1989. He aimed for an intuitive programming language that could appeal to both novice and experienced programmers. Python quickly rose to prominence, consistently ranking among the most popular programming languages globally.\n",
      "\n",
      "Throughout his career, van Rossum has received numerous awards for his contributions, including the Award for the Advancement of Free Software in 2001 and recognition as a Fellow of the Computer History Museum in 2018. As of now, he continues to influence the programming community through his work and innovations, leaving a lasting legacy in the software development field.\n"
     ]
    }
   ],
   "source": [
    "@openai.call(model=\"gpt-4o-mini\")\n",
    "@prompt_template(\n",
    "    \"\"\"\n",
    "    Summarize the following text by first creating an outline with a nested structure,\n",
    "    listing all major topics in the text with subpoints for each of the major points.\n",
    "    The number of subpoints for each topic should correspond to the length and\n",
    "    importance of the major point within the text. Then create the actual summary using\n",
    "    the outline.\n",
    "    {text}\n",
    "    \"\"\"\n",
    ")\n",
    "def summarize_text_with_outline(text: str): ...\n",
    "\n",
    "\n",
    "print(summarize_text_with_outline(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32cc9b09cd2c229",
   "metadata": {},
   "source": [
    "By providing an outline, we enable the LLM to better adhere to the original article's structure, resulting in a more coherent and representative summary.\n",
    "\n",
    "For our next iteration, we'll explore segmenting the document by topic, requesting summaries for each section, and then composing a comprehensive summary using both the outline and these individual segment summaries.\n",
    "\n",
    "## Segment then Summarize\n",
    "\n",
    "This more comprehensive approach not only ensures that the model adheres to the original text's structure but also naturally produces a summary whose length is proportional to the source document, as we combine summaries from each subtopic.\n",
    "\n",
    "To apply this technique, we create a `SegmentedSummary` Pydantic `BaseModel` to contain the outline and section summaries, and extract it in a chained call from the original summarize_text() call:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f0fb6974ae0170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class SegmentedSummary(BaseModel):\n",
    "    outline: str = Field(\n",
    "        ...,\n",
    "        description=\"A high level outline of major sections by topic in the text\",\n",
    "    )\n",
    "    section_summaries: list[str] = Field(\n",
    "        ..., description=\"A list of detailed summaries for each section in the outline\"\n",
    "    )\n",
    "\n",
    "\n",
    "@openai.call(model=\"gpt-4o\", response_model=SegmentedSummary)\n",
    "@prompt_template(\n",
    "    \"\"\"\n",
    "    Extract a high level outline and summary for each section of the following text:\n",
    "    {text}\n",
    "    \"\"\"\n",
    ")\n",
    "def summarize_by_section(text): ...\n",
    "\n",
    "\n",
    "@openai.call(model=\"gpt-4o\")\n",
    "@prompt_template(\n",
    "    \"\"\"\n",
    "    The following contains a high level outline of a text along with summaries of a\n",
    "    text that has been segmented by topic. Create a composite, larger summary by putting\n",
    "    together the summaries according to the outline.\n",
    "    Outline:\n",
    "    {outline}\n",
    "\n",
    "    Summaries:\n",
    "    {summaries}\n",
    "    \"\"\"\n",
    ")\n",
    "def summarize_text_chaining(text: str) -> openai.OpenAIDynamicConfig:\n",
    "    segmented_summary = summarize_by_section(text)\n",
    "    return {\n",
    "        \"computed_fields\": {\n",
    "            \"outline\": segmented_summary.outline,\n",
    "            \"summaries\": segmented_summary.section_summaries,\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "print(summarize_text_chaining(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebdcfd8d1c59177",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip\">\n",
    "<p class=\"admonition-title\">Additional Real-World Applications</p>\n",
    "<ul>\n",
    "<li><b>Meeting Notes</b>: Convert meeting from speech-to-text then summarize the text for reference.</li>\n",
    "<li><b>Education</b>: Create study guides or slides from textbook material using summaries.</li>\n",
    "<li><b>Productivity</b>: Summarize email chains, slack threads, word documents for your day-to-day.</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "When adapting this recipe to your specific use-case, consider the following:\n",
    "    - Refine your prompts to provide clear instructions and relevant context for text summarization.\n",
    "    - Experiment with different model providers and version to balance quality and speed.\n",
    "    - Provide a feedback loop, use an LLM to evaluate the quality of the summary based on a criteria and feed that back into the prompt for refinement.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
