{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6540a4d61b23ccfa",
   "metadata": {},
   "source": [
    "# Self-Ask: Enhancing LLM Reasoning with Follow-Up Questions\n",
    "\n",
    "This recipe demonstrates how to implement the Self-Ask technique using Large Language Models (LLMs) with Mirascope. Self-Ask is a prompt engineering method that enhances an LLM's reasoning capabilities by encouraging it to ask and answer follow-up questions before providing a final answer. We'll explore both a basic implementation and an enhanced version with dynamic example selection.\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "<p class=\"admonition-title\">Additional Real-World Applications</p>\n",
    "<ul>\n",
    "<li><b>Automated Code Generation</b>: Generating boilerplate or units tests for more productivity.</li>\n",
    "<li><b>Code Completion</b>: Give LLM access to web to grab latest docs and generate code autocomplete suggestions.</li>\n",
    "<li><b>Documentation Maintenance</b>: Make sure all documentation code snippets are runnable with proper syntax.</li>\n",
    "<li><b>Prototyping</b>: Generating proof-of-concept applications rather than UI mocks.</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "To set up our environment, first let's install all of the packages we will use:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45916576933cbd81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T13:05:43.218041Z",
     "start_time": "2024-09-30T13:05:36.243448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/koudai/PycharmProjects/mirascope/.venv_notebook/lib/python3.12/site-packages (2.1.1)\r\n",
      "Collecting scikit-learn\r\n",
      "  Downloading scikit_learn-1.5.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: mirascope[openai] in /Users/koudai/PycharmProjects/mirascope/.venv_notebook/lib/python3.12/site-packages (1.2.0)\r\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /Users/koudai/PycharmProjects/mirascope/.venv_notebook/lib/python3.12/site-packages (from mirascope[openai]) (0.16)\r\n",
      "Requirement already satisfied: jiter>=0.5.0 in /Users/koudai/PycharmProjects/mirascope/.venv_notebook/lib/python3.12/site-packages (from mirascope[openai]) (0.5.0)\r\n",
      "Requirement already satisfied: pydantic<3.0,>=2.7.4 in /Users/koudai/PycharmProjects/mirascope/.venv_notebook/lib/python3.12/site-packages (from mirascope[openai]) (2.8.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/koudai/PycharmProjects/mirascope/.venv_notebook/lib/python3.12/site-packages (from mirascope[openai]) (4.12.2)\r\n",
      "Requirement already satisfied: openai<2,>=1.6.0 in /Users/koudai/PycharmProjects/mirascope/.venv_notebook/lib/python3.12/site-packages (from mirascope[openai]) (1.43.0)\r\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\r\n",
      "  Downloading scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\r\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\r\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\r\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\r\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/koudai/PycharmProjects/mirascope/.venv_notebook/lib/python3.12/site-packages (from openai<2,>=1.6.0->mirascope[openai]) (4.4.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/koudai/PycharmProjects/mirascope/.venv_notebook/lib/python3.12/site-packages (from openai<2,>=1.6.0->mirascope[openai]) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/koudai/PycharmProjects/mirascope/.venv_notebook/lib/python3.12/site-packages (from openai<2,>=1.6.0->mirascope[openai]) (0.27.2)\r\n",
      "Requirement already satisfied: sniffio in /Users/koudai/PycharmProjects/mirascope/.venv_notebook/lib/python3.12/site-packages (from openai<2,>=1.6.0->mirascope[openai]) (1.3.1)\r\n",
      "Requirement already satisfied: tqdm>4 in /Users/koudai/PycharmProjects/mirascope/.venv_notebook/lib/python3.12/site-packages (from openai<2,>=1.6.0->mirascope[openai]) (4.66.5)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/koudai/PycharmProjects/mirascope/.venv_notebook/lib/python3.12/site-packages (from pydantic<3.0,>=2.7.4->mirascope[openai]) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/koudai/PycharmProjects/mirascope/.venv_notebook/lib/python3.12/site-packages (from pydantic<3.0,>=2.7.4->mirascope[openai]) (2.20.1)\r\n",
      "Requirement already satisfied: idna>=2.8 in /Users/koudai/PycharmProjects/mirascope/.venv_notebook/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2,>=1.6.0->mirascope[openai]) (3.8)\r\n",
      "Requirement already satisfied: certifi in /Users/koudai/PycharmProjects/mirascope/.venv_notebook/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2,>=1.6.0->mirascope[openai]) (2024.8.30)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/koudai/PycharmProjects/mirascope/.venv_notebook/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2,>=1.6.0->mirascope[openai]) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/koudai/PycharmProjects/mirascope/.venv_notebook/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2,>=1.6.0->mirascope[openai]) (0.14.0)\r\n",
      "Downloading scikit_learn-1.5.2-cp312-cp312-macosx_12_0_arm64.whl (11.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\r\n",
      "Downloading scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl (23.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\r\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\r\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install \"mirascope[openai]\" numpy scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a8cb29dd25ac4d",
   "metadata": {},
   "source": [
    "\n",
    "Make sure to also set your `OPENAI_API_KEY` if you haven't already.\n",
    "\n",
    "## Basic Self-Ask Implementation\n",
    "\n",
    "Let's start with a basic implementation of Self-Ask using few-shot learning examples:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d6981568956d470",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T13:06:56.956555Z",
     "start_time": "2024-09-30T13:06:53.307551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are follow up questions needed here: Yes.  \n",
      "Follow up: Which country is Jayantha Ketagoda from?  \n",
      "Intermediate answer: Jayantha Ketagoda is from Sri Lanka.  \n",
      "Follow up: When did Sri Lanka leave the British Empire?  \n",
      "Intermediate answer: Sri Lanka gained independence from the British Empire on February 4, 1948.  \n",
      "So the final answer is: February 4, 1948.\n",
      "Jayantha Ketagoda was born in Sri Lanka, which was formerly known as Ceylon. Sri Lanka gained independence from the British Empire on February 4, 1948.\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from mirascope.core import openai, prompt_template\n",
    "\n",
    "\n",
    "class FewShotExample(TypedDict):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "\n",
    "@openai.call(model=\"gpt-4o-mini\")\n",
    "@prompt_template(\n",
    "    \"\"\"\n",
    "    Examples:\n",
    "    {examples:lists}\n",
    "\n",
    "    Query: {query}\n",
    "    \"\"\"\n",
    ")\n",
    "def self_ask(query: str, examples: list[FewShotExample]) -> openai.OpenAIDynamicConfig:\n",
    "    return {\n",
    "        \"computed_fields\": {\n",
    "            \"examples\": [\n",
    "                [example[\"question\"], example[\"answer\"]] for example in examples\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "few_shot_examples = [\n",
    "    FewShotExample(\n",
    "        question=\"When does monsoon season end in the state the area code 575 is located?\",\n",
    "        answer=inspect.cleandoc(\n",
    "            \"\"\"\n",
    "            Are follow up questions needed here: Yes.\n",
    "            Follow up: Which state is the area code 575 located in?\n",
    "            Intermediate answer: The area code 575 is located in New Mexico.\n",
    "            Follow up: When does monsoon season end in New Mexico?\n",
    "            Intermediate answer: Monsoon season in New Mexico typically ends in mid-September.\n",
    "            So the final answer is: mid-September.\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ),\n",
    "    FewShotExample(\n",
    "        question=\"What is the current official currency in the country where Ineabelle Diaz is a citizen?\",\n",
    "        answer=inspect.cleandoc(\n",
    "            \"\"\"\n",
    "            Are follow up questions needed here: Yes.\n",
    "            Follow up: Which country is Ineabelle Diaz a citizen of?\n",
    "            Intermediate answer: Ineabelle Diaz is from Peurto Rico, which is in the United States of America.\n",
    "            Follow up: What is the current official currency in the United States of America?\n",
    "            Intermediate answer: The current official currency in the United States is the United States dollar.\n",
    "            So the final answer is: United States dollar.\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ),\n",
    "    FewShotExample(\n",
    "        question=\"Where was the person who founded the American Institute of Public Opinion in 1935 born?\",\n",
    "        answer=inspect.cleandoc(\n",
    "            \"\"\"\n",
    "            Are follow up questions needed here: Yes.\n",
    "            Follow up: Who founded the American Institute of Public Opinion in 1935?\n",
    "            Intermediate answer: George Gallup.\n",
    "            Follow up: Where was George Gallup born?\n",
    "            Intermediate answer: George Gallup was born in Jefferson, Iowa.\n",
    "            So the final answer is: Jefferson.\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ),\n",
    "    FewShotExample(\n",
    "        question=\"What language is used by the director of Tiffany Memorandum?\",\n",
    "        answer=inspect.cleandoc(\n",
    "            \"\"\"\n",
    "            Are follow up questions needed here: Yes.\n",
    "            Follow up: Who directed the movie called Tiffany Memorandum?\n",
    "            Intermediate answer: Sergio Grieco.\n",
    "            Follow up: What language is used by Sergio Grieco?\n",
    "            Intermediate answer: Sergio Grieco speaks Italian.\n",
    "            So the final answer is: Italian.\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ),\n",
    "    FewShotExample(\n",
    "        question=\"What is the sports team the person played for who scored the first touchdown in Superbowl 1?\",\n",
    "        answer=inspect.cleandoc(\n",
    "            \"\"\"\n",
    "            Are follow up questions needed here: Yes.\n",
    "            Follow up: Which player scored the first touchdown in Superbowl 1?\n",
    "            Intermediate answer: Max McGee.\n",
    "            Follow up: Which sports team did Max McGee play for?\n",
    "            Intermediate answer: Max McGee played for the Green Bay Packers.\n",
    "            So the final answer is: Green Bay Packers.\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "query = \"The birth country of Jayantha Ketagoda left the British Empire when?\"\n",
    "response = self_ask(query=query, examples=few_shot_examples)\n",
    "print(response.content)\n",
    "\n",
    "response = self_ask(query=query, examples=[])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d8c8922148a739",
   "metadata": {},
   "source": [
    "\n",
    "This basic implementation demonstrates how to use few-shot learning with Self-Ask. The `self_ask` function takes a query and a list of examples, then uses Mirascope's `OpenAIDynamicConfig` to inject the examples into the prompt.\n",
    "\n",
    "## Enhanced Self-Ask with Dynamic Example Selection\n",
    "\n",
    "Now, let's improve our implementation by adding dynamic example selection:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90bb23253dd60b58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T13:07:51.302652Z",
     "start_time": "2024-09-30T13:07:31.149065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are follow up questions needed here: Yes.  \n",
      "Follow up: Who invented the phonograph?  \n",
      "Intermediate answer: Thomas Edison.  \n",
      "Follow up: What language did Thomas Edison primarily speak?  \n",
      "Intermediate answer: Thomas Edison primarily spoke English.  \n",
      "So the final answer is: English.\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from mirascope.core import openai, prompt_template\n",
    "\n",
    "\n",
    "class FewShotExample(TypedDict):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def select_relevant_examples(\n",
    "    query: str, examples: list[FewShotExample], n: int = 3\n",
    ") -> list[FewShotExample]:\n",
    "    \"\"\"Select the most relevant examples based on cosine similarity.\"\"\"\n",
    "    vectorizer = TfidfVectorizer().fit([ex[\"question\"] for ex in examples] + [query])\n",
    "    example_vectors = vectorizer.transform([ex[\"question\"] for ex in examples])\n",
    "    query_vector = vectorizer.transform([query])\n",
    "\n",
    "    similarities = cosine_similarity(query_vector, example_vectors)[0]\n",
    "    most_similar_indices = np.argsort(similarities)[-n:][::-1]\n",
    "\n",
    "    return [examples[i] for i in most_similar_indices]\n",
    "\n",
    "\n",
    "@openai.call(model=\"gpt-4o-mini\")\n",
    "@prompt_template(\n",
    "    \"\"\"\n",
    "    Examples:\n",
    "    {examples:lists}\n",
    "\n",
    "    Query: {query}\n",
    "    \"\"\"\n",
    ")\n",
    "def dynamic_self_ask(\n",
    "    query: str, examples: list[FewShotExample], n: int = 3\n",
    ") -> openai.OpenAIDynamicConfig:\n",
    "    relevant_examples = select_relevant_examples(query, examples, n)\n",
    "    return {\n",
    "        \"computed_fields\": {\n",
    "            \"examples\": [\n",
    "                [example[\"question\"], example[\"answer\"]]\n",
    "                for example in relevant_examples\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "few_shot_examples = [\n",
    "    FewShotExample(\n",
    "        question=\"When does monsoon season end in the state the area code 575 is located?\",\n",
    "        answer=inspect.cleandoc(\n",
    "            \"\"\"\n",
    "            Are follow up questions needed here: Yes.\n",
    "            Follow up: Which state is the area code 575 located in?\n",
    "            Intermediate answer: The area code 575 is located in New Mexico.\n",
    "            Follow up: When does monsoon season end in New Mexico?\n",
    "            Intermediate answer: Monsoon season in New Mexico typically ends in mid-September.\n",
    "            So the final answer is: mid-September.\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ),\n",
    "    FewShotExample(\n",
    "        question=\"What is the current official currency in the country where Ineabelle Diaz is a citizen?\",\n",
    "        answer=inspect.cleandoc(\n",
    "            \"\"\"\n",
    "            Are follow up questions needed here: Yes.\n",
    "            Follow up: Which country is Ineabelle Diaz a citizen of?\n",
    "            Intermediate answer: Ineabelle Diaz is from Peurto Rico, which is in the United States of America.\n",
    "            Follow up: What is the current official currency in the United States of America?\n",
    "            Intermediate answer: The current official currency in the United States is the United States dollar.\n",
    "            So the final answer is: United States dollar.\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ),\n",
    "    FewShotExample(\n",
    "        question=\"Where was the person who founded the American Institute of Public Opinion in 1935 born?\",\n",
    "        answer=inspect.cleandoc(\n",
    "            \"\"\"\n",
    "            Are follow up questions needed here: Yes.\n",
    "            Follow up: Who founded the American Institute of Public Opinion in 1935?\n",
    "            Intermediate answer: George Gallup.\n",
    "            Follow up: Where was George Gallup born?\n",
    "            Intermediate answer: George Gallup was born in Jefferson, Iowa.\n",
    "            So the final answer is: Jefferson.\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ),\n",
    "    FewShotExample(\n",
    "        question=\"What language is used by the director of Tiffany Memorandum?\",\n",
    "        answer=inspect.cleandoc(\n",
    "            \"\"\"\n",
    "            Are follow up questions needed here: Yes.\n",
    "            Follow up: Who directed the movie called Tiffany Memorandum?\n",
    "            Intermediate answer: Sergio Grieco.\n",
    "            Follow up: What language is used by Sergio Grieco?\n",
    "            Intermediate answer: Sergio Grieco speaks Italian.\n",
    "            So the final answer is: Italian.\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ),\n",
    "    FewShotExample(\n",
    "        question=\"What is the sports team the person played for who scored the first touchdown in Superbowl 1?\",\n",
    "        answer=inspect.cleandoc(\n",
    "            \"\"\"\n",
    "            Are follow up questions needed here: Yes.\n",
    "            Follow up: Which player scored the first touchdown in Superbowl 1?\n",
    "            Intermediate answer: Max McGee.\n",
    "            Follow up: Which sports team did Max McGee play for?\n",
    "            Intermediate answer: Max McGee played for the Green Bay Packers.\n",
    "            So the final answer is: Green Bay Packers.\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "query = \"What was the primary language spoken by the inventor of the phonograph?\"\n",
    "response = dynamic_self_ask(query=query, examples=few_shot_examples, n=2)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a35b57a5ed44ce6",
   "metadata": {},
   "source": [
    "\n",
    "This enhanced version introduces the `select_relevant_examples` function, which uses TF-IDF vectorization and cosine similarity to find the most relevant examples for a given query. The `dynamic_self_ask` function then selects these relevant examples before including them in the prompt.\n",
    "\n",
    "## Benefits and Considerations\n",
    "\n",
    "The enhanced Self-Ask implementation offers several advantages:\n",
    "\n",
    "1. Reduced prompt size by including only the most relevant examples.\n",
    "2. Potentially improved response quality by focusing on the most applicable few-shot examples.\n",
    "3. Ability to maintain a larger pool of examples without always including all of them in every query.\n",
    "\n",
    "When implementing this technique, consider:\n",
    "\n",
    "- Balancing the number of selected examples with the desired prompt length and model context window.\n",
    "- Experimenting with different similarity metrics or embedding techniques for example selection.\n",
    "- Regularly updating your example pool to cover a wide range of query types and topics.\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "<p class=\"admonition-title\">Additional Real-World Applications</p>\n",
    "<ul>\n",
    "<li><b>Complex Problem Solving</b>: Use Self-Ask for multi-step problems in fields like mathematics or engineering.</li>\n",
    "<li><b>Research Assistance</b>: Implement Self-Ask to help researchers explore complex topics and formulate hypotheses.</li>\n",
    "<li><b>Legal Analysis</b>: Apply Self-Ask to break down complex legal questions and explore relevant precedents.</li>\n",
    "<li><b>Medical Diagnosis</b>: Use Self-Ask to guide through differential diagnosis processes.</li>\n",
    "<li><b>Customer Support</b>: Implement Self-Ask to handle complex customer queries that require multiple pieces of information.</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "\n",
    "When adapting this recipe to your specific use-case, consider:\n",
    "\n",
    "- Tailoring the few-shot examples to your domain for better performance.\n",
    "- Experimenting with different prompts and example formats to optimize the Self-Ask process.\n",
    "- Implementing a feedback loop to continuously improve the quality of the Self-Ask responses.\n",
    "- Combining Self-Ask with other techniques like chain-of-thought for even more powerful reasoning capabilities.\n",
    "\n",
    "By leveraging Mirascope's `call` decorator and `prompt_template`, you can easily implement and customize the Self-Ask technique to enhance your LLM's reasoning capabilities across a wide range of applications.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
