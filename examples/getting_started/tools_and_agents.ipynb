{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Tools and Agents in Mirascope\n",
    "\n",
    "This notebook provides a detailed introduction to using Tools and implementing Agents in Mirascope. We'll use the WebSearchAgent as our primary example to demonstrate these concepts.\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Setting Up the Environment](#Setting-Up-the-Environment)\n",
    "3. [Understanding Tools in Mirascope](#Understanding-Tools-in-Mirascope)\n",
    "4. [Creating Custom Tools](#Creating-Custom-Tools)\n",
    "5. [Introduction to Agents](#Introduction-to-Agents)\n",
    "6. [Implementing the WebSearchAgent](#Implementing-the-WebSearchAgent)\n",
    "7. [Running and Testing the Agent](#Running-and-Testing-the-Agent)\n",
    "8. [Advanced Concepts and Best Practices](#Advanced-Concepts-and-Best-Practices)\n",
    "9. [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Tools and Agents are two key concepts in building advanced AI systems, particularly those involving Large Language Models (LLMs):\n",
    "\n",
    "- **Tools**: Functions that extend the capabilities of LLMs, allowing them to perform specific tasks or access external data.\n",
    "- **Agents**: Autonomous or semi-autonomous entities that use LLMs and Tools to perform complex tasks or interact with users.\n",
    "\n",
    "In this notebook, we'll explore how to create and use Tools, and how to implement an Agent using the WebSearchAgent as our example. We'll be using Mirascope, a framework that simplifies the process of building LLM-powered applications with tools and agents.\n",
    "\n",
    "For more detailed information on these concepts, refer to the following Mirascope documentation:\n",
    "\n",
    "- [Tools documentation](https://docs.mirascope.io/latest/learn/tools/)\n",
    "- [Agents documentation](https://docs.mirascope.io/latest/learn/agents/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting Up the Environment\n",
    "\n",
    "First, let's set up our environment by installing Mirascope and other necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"mirascope[openai]\" duckduckgo_search beautifulsoup4 requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "For more information on setting up Mirascope and its dependencies, see the [Mirascope installation guide](https://docs.mirascope.io/latest/get-started/)."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Understanding Tools in Mirascope\n",
    "\n",
    "In Mirascope, Tools are functions that extend the capabilities of LLMs. They allow the LLM to perform specific tasks or access external data. Tools are typically used to:\n",
    "\n",
    "1. Retrieve information from external sources\n",
    "2. Perform calculations or data processing\n",
    "3. Interact with APIs or databases\n",
    "4. Execute specific actions based on the LLM's decisions\n",
    "\n",
    "Let's start by creating a simple Tool that extracts content from a webpage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T05:49:48.725564Z",
     "start_time": "2024-09-10T05:49:48.658370Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def extract_content(url: str) -> str:\n",
    "    \"\"\"Extract the main content from a webpage.\n",
    "\n",
    "    Args:\n",
    "        url: The URL of the webpage to extract the content from.\n",
    "\n",
    "    Returns:\n",
    "        The extracted content as a string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        unwanted_tags = [\"script\", \"style\", \"nav\", \"header\", \"footer\", \"aside\"]\n",
    "        for tag in unwanted_tags:\n",
    "            for element in soup.find_all(tag):\n",
    "                element.decompose()\n",
    "\n",
    "        main_content = (\n",
    "            soup.find(\"main\")\n",
    "            or soup.find(\"article\")\n",
    "            or soup.find(\"div\", class_=re.compile(\"content|main\"))\n",
    "        )\n",
    "\n",
    "        if main_content:\n",
    "            text = main_content.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "        lines = (line.strip() for line in text.splitlines())\n",
    "        return \"\\n\".join(line for line in lines if line)\n",
    "    except Exception as e:\n",
    "        return f\"{type(e)}: Failed to extract content from URL {url}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `extract_content` function is a Tool that takes a URL as input and returns the main content of the webpage as a string. It uses BeautifulSoup to parse the HTML and extract the relevant text content.\n",
    "\n",
    "For more details on implementing and using Tools in Mirascope, see the [Tools documentation](https://docs.mirascope.io/latest/learn/tools/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating Custom Tools\n",
    "\n",
    "Now, let's create a more complex Tool that performs web searches using the DuckDuckGo search engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T05:49:51.530045Z",
     "start_time": "2024-09-10T05:49:51.510653Z"
    }
   },
   "outputs": [],
   "source": [
    "from duckduckgo_search import DDGS\n",
    "\n",
    "\n",
    "def web_search(queries: list[str], max_results_per_query: int = 2) -> str:\n",
    "    \"\"\"Performs web searches for given queries and returns URLs.\n",
    "\n",
    "    Args:\n",
    "        queries: List of search queries.\n",
    "        max_results_per_query: Maximum number of results to return per query.\n",
    "\n",
    "    Returns:\n",
    "        str: Newline-separated URLs from search results or error messages.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If web search fails entirely.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        urls = []\n",
    "        for query in queries:\n",
    "            results = DDGS(proxies=None).text(query, max_results=max_results_per_query)\n",
    "\n",
    "            for result in results:\n",
    "                link = result[\"href\"]\n",
    "                try:\n",
    "                    urls.append(link)\n",
    "                except Exception as e:\n",
    "                    urls.append(f\"{type(e)}: Failed to parse content from URL {link}\")\n",
    "        return \"\\n\\n\".join(urls)\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"{type(e)}: Failed to search the web for text\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `web_search` function is a more complex Tool that takes a list of search queries and returns a string of newline-separated URLs from the search results. It uses the DuckDuckGo search API to perform the searches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Introduction to Agents\n",
    "\n",
    "Agents in Mirascope are autonomous or semi-autonomous entities that use LLMs and Tools to perform complex tasks or interact with users. They typically have:\n",
    "\n",
    "1. A state (e.g., conversation history, search history)\n",
    "2. Access to one or more Tools\n",
    "3. A method for interacting with an LLM\n",
    "4. A main loop or execution flow\n",
    "\n",
    "Let's start implementing our WebSearchAgent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T05:49:55.059472Z",
     "start_time": "2024-09-10T05:49:54.640424Z"
    }
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "from mirascope.core import BaseMessageParam, openai\n",
    "\n",
    "\n",
    "class WebAssistantBase(BaseModel):\n",
    "    messages: list[BaseMessageParam | openai.OpenAIMessageParam] = []\n",
    "    search_history: list[str] = []\n",
    "    max_results_per_query: int = 2\n",
    "\n",
    "    def _web_search(self, queries: list[str]) -> str:\n",
    "        \"\"\"Wrapper for the web_search function that updates search history.\"\"\"\n",
    "        result = web_search(queries, self.max_results_per_query)\n",
    "        self.search_history.extend(queries)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `WebAssistant` class forms the base of our Agent. It has:\n",
    "\n",
    "- A `messages` list to store the conversation history\n",
    "- A `search_history` list to keep track of past searches\n",
    "- A `max_results_per_query` parameter to control the number of search results\n",
    "- A `_web_search` method that wraps our `web_search` Tool and updates the search history\n",
    "\n",
    "To learn more about the concept of Agents in Mirascope, refer to the [Agents documentation](https://docs.mirascope.io/latest/learn/agents/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Implementing the WebSearchAgent\n",
    "\n",
    "Now, let's add the LLM interaction and main execution flow to our WebSearchAgent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T05:49:57.403378Z",
     "start_time": "2024-09-10T05:49:57.386942Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from mirascope.core import openai, prompt_template\n",
    "\n",
    "\n",
    "class WebAssistant(WebAssistantBase):\n",
    "    @openai.call(model=\"gpt-4o-mini\", stream=True)\n",
    "    @prompt_template(\n",
    "        \"\"\"\n",
    "        SYSTEM:\n",
    "        You are an expert web searcher. Your task is to answer the user's question using the provided tools.\n",
    "        The current date is {current_date}.\n",
    "\n",
    "        You have access to the following tools:\n",
    "        - `_web_search`: Search the web when the user asks a question. Follow these steps for EVERY web search query:\n",
    "            1. There is a previous search context: {self.search_history}\n",
    "            2. There is the current user query: {question}\n",
    "            3. Given the previous search context, generate multiple search queries that explores whether the new query might be related to or connected with the context of the current user query. \n",
    "                Even if the connection isn't immediately clear, consider how they might be related.\n",
    "        - `extract_content`: Parse the content of a webpage.\n",
    "\n",
    "        When calling the `_web_search` tool, the `body` is simply the body of the search\n",
    "        result. You MUST then call the `extract_content` tool to get the actual content\n",
    "        of the webpage. It is up to you to determine which search results to parse.\n",
    "\n",
    "        Once you have gathered all of the information you need, generate a writeup that\n",
    "        strikes the right balance between brevity and completeness based on the context of the user's query.\n",
    "\n",
    "        MESSAGES: {self.messages}\n",
    "        USER: {question}\n",
    "        \"\"\"\n",
    "    )\n",
    "    async def _stream(self, question: str) -> openai.OpenAIDynamicConfig:\n",
    "        return {\n",
    "            \"tools\": [self._web_search, extract_content],\n",
    "            \"computed_fields\": {\n",
    "                \"current_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            },\n",
    "        }\n",
    "\n",
    "    async def _step(self, question: str):\n",
    "        response = await self._stream(question)\n",
    "        tools_and_outputs = []\n",
    "        async for chunk, tool in response:\n",
    "            if tool:\n",
    "                print(f\"using {tool._name()} tool with args: {tool.args}\")\n",
    "                tools_and_outputs.append((tool, tool.call()))\n",
    "            else:\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "        if response.user_message_param:\n",
    "            self.messages.append(response.user_message_param)\n",
    "        self.messages.append(response.message_param)\n",
    "        if tools_and_outputs:\n",
    "            self.messages += response.tool_message_params(tools_and_outputs)\n",
    "            await self._step(\"\")\n",
    "\n",
    "    async def run(self):\n",
    "        while True:\n",
    "            question = input(\"(User): \")\n",
    "            if question == \"exit\":\n",
    "                break\n",
    "            print(\"(Assistant): \", end=\"\", flush=True)\n",
    "            await self._step(question)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation includes:\n",
    "\n",
    "1. The `_stream` method, which sets up the LLM call with the necessary tools and computed fields.\n",
    "2. The `_step` method, which processes the LLM response, handles tool calls, and updates the conversation history.\n",
    "3. The `run` method, which implements the main interaction loop for the agent.\n",
    "\n",
    "The `@openai.call` and `@prompt_template` decorators are used to set up the LLM interaction and define the prompt for the agent.\n",
    "\n",
    "For more information on creating custom Agents and advanced Agent patterns, see the [Agents documentation](https://docs.mirascope.io/latest/learn/agents/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Running and Testing the Agent\n",
    "\n",
    "Now that we have implemented our WebSearchAgent, let's run and test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T05:51:14.689791Z",
     "start_time": "2024-09-10T05:50:01.156793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Assistant): using _web_search tool with args: {'queries': ['what is a Large Language Model', 'applications of Large Language Models', 'how do Large Language Models work', 'limitations of Large Language Models', 'ethics of Large Language Models', 'recent advancements in Large Language Models']}\n",
      "using extract_content tool with args: {'url': 'https://www.ibm.com/topics/large-language-models'}\n",
      "using extract_content tool with args: {'url': 'https://en.wikipedia.org/wiki/Large_language_model'}\n",
      "using extract_content tool with args: {'url': 'https://medium.com/@researchgraph/the-journey-of-large-language-models-evolution-application-and-limitations-c72461bf3a6f'}\n",
      "using extract_content tool with args: {'url': 'https://blogs.nvidia.com/blog/what-are-large-language-models-used-for/'}\n",
      "using extract_content tool with args: {'url': 'https://arstechnica.com/science/2023/07/a-jargon-free-explanation-of-how-ai-large-language-models-work/'}\n",
      "### Overview of Large Language Models (LLMs)\n",
      "\n",
      "Large Language Models (LLMs) are advanced artificial intelligence systems designed to understand and generate human language by learning from vast datasets. Their architecture relies on deep learning techniques, specifically transformer models, which enable them to handle sequential data efficiently. These models have gained significant popularity due to their ability to perform a wide range of language-related tasks, from text generation to translation and summarization.\n",
      "\n",
      "#### Key Characteristics of LLMs\n",
      "1. **Data-Driven**: LLMs are trained on extensive corpuses, encompassing a substantial portion of the internet and diverse textual sources. This training involves self-supervised learning, allowing them to learn statistical relationships within the text.\n",
      "  \n",
      "2. **Transformers**: The architecture of LLMs typically involves transformers, which utilize mechanisms like self-attention to focus on different parts of the input text for better understanding and generation capabilities.\n",
      "\n",
      "3. **Generative Capabilities**: LLMs do not merely perform tasks; they can create text that is coherent and contextually relevant. This feature is vital for applications such as chatbots, content generation, and automated summarization.\n",
      "\n",
      "4. **Customization and Fine-Tuning**: Although LLMs can operate as generalists, they can also be fine-tuned for specific tasks or industries, enhancing their performance in specialized applications.\n",
      "\n",
      "### Applications of LLMs\n",
      "LLMs have a broad range of applications across various sectors:\n",
      "- **Healthcare**: Automating patient interactions, generating physician notes, and assisting in medical diagnosis.\n",
      "- **Education**: Providing tutoring, generating educational content, and aiding in research.\n",
      "- **Finance**: Analyzing trends, generating reports, and assisting in predictive analytics.\n",
      "- **Customer Service**: Powering chatbots and virtual assistants that provide customer support and troubleshooting.\n",
      "- **Software Development**: Assisting in code generation and software troubleshooting.\n",
      "\n",
      "### Limitations and Challenges\n",
      "Despite their capabilities, LLMs face significant challenges:\n",
      "- **Bias and Ethical Concerns**: LLMs may inherit biases present in the training data, leading to skewed representations and outputs.\n",
      "- **Computation and Resource Intensity**: Training and running these models require immense computational power and resources, which can be a barrier to entry for many organizations.\n",
      "- **Interpretability**: Understanding how LLMs arrive at specific outputs is challenging. They often operate as \"black boxes,\" leading to difficulties in trust and accountability.\n",
      "\n",
      "### Future of LLMs\n",
      "As research in AI continues to evolve, LLMs are expected to incorporate more advanced functionalities and applications. There is a growing focus on improving their interpretability, reducing biases, and developing more efficient training methods to make these powerful tools accessible and responsible.\n",
      "\n",
      "### Conclusion\n",
      "LLMs represent a significant leap in natural language processing and artificial intelligence. They are reshaping how we interact with technology and are poised to become integral to various industries, driving innovation and efficiency in processes previously reliant on human input. As these models evolve, addressing their limitations and ethical implications will be crucial for their responsible deployment in society.\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    web_assistant = WebAssistant()\n",
    "    await web_assistant.run()\n",
    "\n",
    "\n",
    "# Run main in a jupyter notebook\n",
    "await main()\n",
    "\n",
    "# Run main in a python script\n",
    "# asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the WebSearchAgent, run the code above and start interacting with it by typing your questions. The agent will use web searches and content extraction to provide answers. Type 'exit' to end the interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Advanced Concepts and Best Practices\n",
    "\n",
    "When working with Tools and Agents in Mirascope, consider the following best practices:\n",
    "\n",
    "1. **Error Handling**: Implement robust error handling in your Tools and Agent implementation.\n",
    "2. **Rate Limiting**: Be mindful of rate limits when using external APIs in your Tools.\n",
    "3. **Caching**: Implement caching mechanisms to improve performance and reduce API calls.\n",
    "4. **Testing**: Write unit tests for your Tools and integration tests for your Agents.\n",
    "5. **Modularity**: Design your Tools and Agents to be modular and reusable.\n",
    "6. **Security**: Be cautious about the information you expose through your Tools and Agents.\n",
    "7. **Logging**: Implement logging to track the behavior and performance of your Agents.\n",
    "\n",
    "For more advanced usage, you can explore concepts like:\n",
    "\n",
    "- Multi-agent systems\n",
    "- Tool chaining and composition\n",
    "- Dynamic tool selection\n",
    "- Memory and state management for long-running agents\n",
    "\n",
    "For more advanced techniques and best practices in using Mirascope, refer to the following documentation:\n",
    "\n",
    "- [Dynamic Configuration](https://docs.mirascope.io/latest/learn/dynamic_configuration/)\n",
    "- [Chaining](https://docs.mirascope.io/latest/learn/chaining/)\n",
    "- [Streams](https://docs.mirascope.io/latest/learn/streams/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "In this notebook, we've explored the basics of creating Tools and implementing Agents in Mirascope. We've built a WebSearchAgent that can perform web searches, extract content from webpages, and use an LLM to generate responses based on the gathered information.\n",
    "\n",
    "This example demonstrates the power and flexibility of Mirascope in building AI applications that combine LLMs with custom tools and logic. As you continue to work with Mirascope, you'll discover more advanced features and patterns that can help you build even more sophisticated AI agents and applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
